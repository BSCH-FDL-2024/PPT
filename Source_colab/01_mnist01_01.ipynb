{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUaAUVEDO-wb"
   },
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9jPk8mIO-wg"
   },
   "source": [
    "# MNIST 데이터세트로 이미지 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkeMK221O-wg"
   },
   "source": [
    "이 섹션에서는 딥러닝의 \"Hello World\"를 수행하여 수기 문자를 올바르게 분류하도록 딥러닝 모델을 트레이닝해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcFpUg9gO-wg"
   },
   "source": [
    "## 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUO-zYFLO-wh"
   },
   "source": [
    "* 딥러닝이 기존의 프로그래밍 메서드로는 불가능했던 문제를 어떻게 해결할 수 있는지 이해\n",
    "* [MNSIT 수기 문자 데이터세트](http://yann.lecun.com/exdb/mnist/)에 대해 알아보기\n",
    "* [Keras API](https://keras.io/)를 사용하여 MNIST 데이터세트를 로드하고 트레이닝을 위해 준비\n",
    "* 단순한 뉴럴 네트워크를 구축하여 이미지 분류 수행\n",
    "* 준비된 MNIST 데이터세트를 사용하여 뉴럴 네트워크 트레이닝\n",
    "* 트레이닝된 뉴럴 네트워크의 성능 관찰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xci05-9pO-wh"
   },
   "source": [
    "## 문제: 이미지 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqWIehr0O-wh"
   },
   "source": [
    "기존 프로그래밍에서는 프로그래머가 코드에 규칙과 조건을 설명할 수 있으며, 프로그램은 이를 사용하여 올바른 방식으로 동작할 수 있습니다. 이 접근 방식은 매우 다양한 문제에 대해 계속해서 뛰어난 효과를 보여줍니다.\n",
    "\n",
    "처음 접한 이미지를 정확한 클래스로 올바르게 분류하도록 프로그램에 요청하는 이미지 분류는 기존 프로그래밍 기술로는 해결하기가 거의 불가능합니다. 특히 처음 접하는 이미지를 고려할 때 어떻게 해서 프로그래머가 매우 다양한 이미지를 올바르게 분류하기 위한 규칙과 조건을 정의할 수 있을까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYUJ4kWzO-wh"
   },
   "source": [
    "## 솔루션: 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpFnOjZbO-wi"
   },
   "source": [
    "딥러닝은 시행착오를 통한 패턴 인식에 뛰어난 면모를 보입니다. 충분한 데이터로 딥 뉴럴 네트워크를 트레이닝하고 트레이닝을 통해 성능에 대한 피드백을 네트워크에 제공함으로써 네트워크는 엄청난 수의 반복이 요구되기는 하지만 그래도 올바른 방식으로 작동할 수 있는 기준이 되는 나름의 조건을 식별할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dyo9PqdkO-wi"
   },
   "source": [
    "## MNIST 데이터세트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ4ogZhGO-wi"
   },
   "source": [
    "딥러닝의 역사에서, 0~9의 수기 문자로 구성된 70,000개의 회색조 이미지가 모여 있는 [MNSIT 데이터세트](http://yann.lecun.com/exdb/mnist/)의 정확한 이미지 분류는 엄청난 발전이었습니다. 오늘날에는 문제가 사소하게 여겨지고 있지만 MNIST를 사용한 이미지 분류 수행은 딥러닝의 \"Hello World\"와 같은 것이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKdp6vQjO-wi"
   },
   "source": [
    "다음은 MNIST 데이터세트에 포함된 이미지 중 40개입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaKy2uWoO-wi"
   },
   "source": [
    "<img src=\"./images/mnist1.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwsvTEQ7O-wj"
   },
   "source": [
    "## 트레이닝 및 검증 데이터 및 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6EE7mmsO-wj"
   },
   "source": [
    "딥러닝을 위해 이미지로 작업할 때에는 이미지 자체(대개 `X`로 표시됨)뿐 아니라 이러한 이미지의 올바른 [레이블](https://developers.google.com/machine-learning/glossary#label)(대개 `Y`로 표시됨)가 모두 필요합니다. 아울러, 모델 *트레이닝*을 위한 `X` 및 `Y` 값이 둘 다 필요하며, 트레이닝된 이후의 모델 성능 *검증*을 위한 별도의 `X` 및 `Y` 값이 필요합니다. 따라서 MNIST 데이터세트에는 다음 4개의 데이터 세그먼트가 필요합니다.\n",
    "\n",
    "1. `x_train`: 뉴럴 네트워크를 트레이닝하는 데 사용되는 이미지\n",
    "2. `y_train`: `x_train` 트레이닝 중 모델의 예측을 평가하는 데 사용되는 올바른 이미지 레이블\n",
    "3. `x_valid`: 트레이닝된 모델의 성능 검증을 위해 따로 확보해 놓는 이미지\n",
    "4. `y_valid`: `x_valid` 트레이닝 후 모델의 예측을 평가하는 데 사용되는 올바른 이미지 레이블\n",
    "\n",
    "분석을 위한 데이터 준비 과정을 [데이터 엔지니어링](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)이라고 부릅니다. 트레이닝 데이터와 검증 데이터(및 테스트 데이터) 간의 차이점에 대해 자세히 알아보려면 Jason Browlee가 작성한 [이 문서](https://machinelearningmastery.com/difference-test-validation-datasets/)를 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEii8f14O-wj"
   },
   "source": [
    "## 데이터를 메모리에 로드(Keras 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPnlWl2hO-wj"
   },
   "source": [
    "다수의 [딥러닝 프레임워크](https://developer.nvidia.com/deep-learning-frameworks)가 존재하며, 각자 나름의 장점을 지니고 있습니다. 이 워크숍에서는 [Tensorflow 2](https://www.tensorflow.org/tutorials/quickstart/beginner), 구체적으로는 [Keras API](https://keras.io/)를 사용할 것입니다. Keras에는 컴퓨터 비전 작업을 위해 고안된 다수의 유용한 기능이 내장되어 있습니다. [가독성](https://blog.pragmaticengineer.com/readable-code/) 및 효율성 덕분에 전문가적 환경에서 딥러닝을 위한 타당한 선택이기도 합니다. 하지만 Keras만 그런 것이 아니므로 딥러닝 프로젝트를 시작할 때는 다양한 프레임워크를 살펴볼 가치가 있습니다.\n",
    "\n",
    "Keras가 제공하는 여러 유용한 기능 중 하나는 MNIST를 비롯한 [여러 공통 데이터 세트](https://www.tensorflow.org/api_docs/python/tf/keras/datasets)를 위한 다수의 헬퍼 메서드를 포함하는 모듈입니다.\n",
    "\n",
    "먼저 MNIST를 위한 Keras 데이터세트를 로드해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "YkUQgTjSO-wj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pabp2sREO-wk"
   },
   "source": [
    "`mnist` 모듈의 경우 트레이닝 및 검증을 위해 이미지와 레이블로 미리 분할되어 있는 MNIST 데이터를 쉽게 로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "J0_FjBegO-wk"
   },
   "outputs": [],
   "source": [
    "# the data, split between train and validation sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10idks79O-wk"
   },
   "source": [
    "## MNIST 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5fEPL99O-wk"
   },
   "source": [
    "앞서 언급했던 것처럼 MNIST 데이터세트에는 수기 문자로 이루어진 70,000개의 회색조 이미지가 포함되어 있습니다. 다음 셀을 실행하면 Keras가 트레이닝을 위해 60,000개의 이미지, 검증(트레이닝 후)을 위해 10,000개의 이미지를 분할했으며 각 이미지 자체가 28x28 차원의 2D 어레이임을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "dAEMBmVfO-wk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "UVY21LYNO-wl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtyYN9tsO-wl"
   },
   "source": [
    "뿐만 아니라, 이러한 28x28 이미지가 0~255의 서명되지 않은 8비트 정수 값 모음으로 표현되는 것을 확인할 수 있습니다. 이는 픽셀의 회색조 값에 해당하는 값들로, `0`은 검은색, `255`는 흰색, 그리고 나머지 모든 값은 둘 사이의 값에 해당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfFqfbS3O-wl"
   },
   "outputs": [],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dv81Ebu2O-wl"
   },
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvd7C-SWO-wl"
   },
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yRXDLDuO-wl"
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rYHgEmHO-wl"
   },
   "source": [
    "[Matplotlib](https://matplotlib.org/)를 사용하면 데이터세트에서 이러한 회색조 이미지 중 하나를 렌더링할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "zHMjr3LjO-wm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f00f40d92b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = x_train[1]\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJ0W1TCQO-wm"
   },
   "source": [
    "이렇게 하면 이것이 5의 28x28 픽셀 이미지임을 알 수 있습니다. 아니면 3일까요? 답은 데이터의 올바른 레이블을 포함하는 `y_train` 데이터에 있습니다. 한번 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ymTqkhn0O-wm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sI3AOItwO-wm"
   },
   "source": [
    "## 트레이닝을 위한 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kn9CaUCO-wm"
   },
   "source": [
    "딥러닝에서는 대부분의 경우 트레이닝을 위한 적합한 상태로 데이터를 변환해야 합니다. 이러한 특정 이미지 분류 문제의 경우, 트레이닝을 준비하는 과정에서 데이터에 3가지 작업을 수행해야 합니다.\n",
    "1. 이미지 데이터를 평탄화하여 모델에 입력되는 이미지를 간소화해야 합니다.\n",
    "2. 이미지 데이터를 정규화하여 이미지 입력 값이 모델에서 더 쉽게 작동되도록 해야 합니다.\n",
    "3. 레이블을 분류하여 레이블 값이 모델에서 더 쉽게 작동되도록 해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zzq41ZYTO-wm"
   },
   "source": [
    "### 이미지 데이터 평탄화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAk4u_KTO-wm"
   },
   "source": [
    "딥러닝 모델에서 2차원 이미지(우리 경우에는 28x28픽셀)를 사용할 수도 있긴 하지만 여기서는 간단하게 각 이미지를 784개의 연속 픽셀(참고: 28x28 = 784)로 이루어진 단일 어레이로 [재구성(reshape)](https://www.tensorflow.org/api_docs/python/tf/reshape)하겠습니다. 이는 이미지 평탄화라고도 불립니다.\n",
    "\n",
    "여기서는 헬퍼 메서드 `reshape`를 사용하여 이를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "HT82Y225O-wn"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAmd6UbeO-wn"
   },
   "source": [
    "이미지가 재구성되어 각 784개의 픽셀 값을 포함하는 1D 어레이의 모음이 되었음을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "sraGop3fO-wn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "n9WVu2vDO-wn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryBXOszJO-wn"
   },
   "source": [
    "### 이미지 데이터 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TghQqDvO-wn"
   },
   "source": [
    "딥러닝 모델은 0에서 1 사이의 부동 소수점 수를 처리하는 데 더 뛰어납니다(이 주제에 대해서는 나중에 자세히 다루겠습니다). 정수 값을 0에서 1 사이의 부동 소수점 값으로 변환하는 것을 [정규화](https://developers.google.com/machine-learning/glossary#normalization)라고 하며, 여기서는 데이터를 정규화하기 위해 모든 픽셀 값(앞에서 언급했던 것처럼 0~255)을 255로 나누는 단순한 접근 방법을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ePhWK6g2O-wn"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cBTjx36O-wo"
   },
   "source": [
    "이제 값이 모두 `0.0`~`1.0`의 부동 소수점 값으로 변환되었음을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "64nu_i3YO-wo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "HnZc7sy1O-wo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "KN_dTacaO-wo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxOR2C9HO-wo"
   },
   "source": [
    "### 범주 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0r5drlyuO-wo"
   },
   "source": [
    "7 - 2의 답이 뭐냐고 묻는 질문을 받는다고 가정해 보겠습니다. 4라고 답하는 것은 9라고 답하는 것보다 훨씬 정답에 근접합니다. 하지만 이러한 이미지 분류 문제의 경우 뉴럴 네트워크가 이런 종류의 추론을 배우지 않도록 하는 것이 좋습니다. 그냥 올바른 범주를 선택하고 숫자 5의 이미지가 있는 경우 4를 추측하는 것이 9를 추측하는 것 만큼이나 나쁘다는 점을 이해하도록 해야 합니다.\n",
    "\n",
    "이미지의 레이블은 현재 상태 그대로 0~9의 정수입니다. 이러한 값이 숫자 범위를 나타내므로, 모델은 올바른 숫자 범주에 얼마나 근접하게 추측하는지에 따라 성능에 대한 어떤 결론을 내리려 할 수도 있습니다.\n",
    "\n",
    "따라서 여기서는 데이터에 범주 인코딩이라는 작업을 수행하겠습니다. 이러한 변환은 이 특정 값이 true로 설정된 실제 범주를 포함해 각 값이 가능한 모든 범주의 모음이 되도록 데이터를 수정합니다.\n",
    "\n",
    "간단히 예를 들면, 빨간색, 파란색, 초록색, 이렇게 3개의 범주가 있다고 가정해 보겠습니다. 주어진 색상에 대해 이러한 범주 중 둘은 false, 나머지 하나는 true가 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CorHkyKkO-wo"
   },
   "source": [
    "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
    "|------------|---------|----------|----------|\n",
    "|Red|True|False|False|\n",
    "|Green|False|False|True|\n",
    "|Blue|False|True|False|\n",
    "|Green|False|False|True|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbTO0JV8O-wp"
   },
   "source": [
    "\"True\" 또는 \"False\"를 사용하는 대신 0 또는 1의 바이너리를 사용하여 같은 내용을 표현할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsYZqvvvO-wp"
   },
   "source": [
    "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
    "|------------|---------|----------|----------|\n",
    "|Red|1|0|0|\n",
    "|Green|0|0|1|\n",
    "|Blue|0|1|0|\n",
    "|Green|0|0|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXVgZFGYO-wp"
   },
   "source": [
    "이것이 범주 인코딩 즉, 범주 레이블로 이해되어야 하는 값을 모델이 범주 특성을 알 수 있는 표현으로 변환하는 것입니다. 따라서 다음의 값을 트레이닝에 사용할 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYpmMnOAO-wp"
   },
   "source": [
    "```python\n",
    "values = ['red, green, blue, green']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5tcKE71O-wp"
   },
   "source": [
    "... 뉴럴 네트워크가 이를 이해하기는 매우 어렵기에 다음과 같이 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-teSgv3O-wp"
   },
   "source": [
    "```python\n",
    "values = [\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdNfBBvwO-wp"
   },
   "source": [
    "### 레이블 범주 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMlx5CjnO-wq"
   },
   "source": [
    "Keras는 [값을 범주 인코딩](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)하는 유틸리티를 제공하며, 여기서는 이를 사용하여 트레이닝 및 검증 레이블 모두에 대한 범주 인코딩을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "kkO0jDSsO-wq"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_categories = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_test = keras.utils.to_categorical(y_test, num_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kaw6pvbIO-wq"
   },
   "source": [
    "다음은 트레이닝 레이블과 관련된 첫 번째 10개 값으로, 지금은 범주 인코딩이 되어 있는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "3-l7ftU6O-wq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maoh1iVjO-wq"
   },
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHKjh_Z8O-wq"
   },
   "source": [
    "트레이닝을 위한 데이터가 준비되었으니 이제 데이터로 트레이닝할 모델을 생성해야 합니다. 이 첫 번째 기본 모델은 여러 개의 *레이어*로 이루어지며 3가지 주요 부분으로 구성됩니다.\n",
    "\n",
    "1. 어느 정도 예상되는 형식으로 데이터를 수신하는 입력 레이어\n",
    "2. 각각 다수의 *뉴런*으로 구성된 여러 개의 [숨겨진 레이어](https://developers.google.com/machine-learning/glossary#hidden-layer) 각 [뉴런](https://developers.google.com/machine-learning/glossary#neuron)은 *가중치*로 네트워크의 추측에 영향을 미칠 수 있으며, 가중치는 네트워크가 수많은 반복을 통해 성능에 대한 피드백을 수신하고 학습하면서 업데이트하게 되는 값입니다.\n",
    "3. 주어진 이미지에 대한 네트워크의 추측을 보여주는 출력 레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvLbQJ3SO-wq"
   },
   "source": [
    "### 모델 인스턴스화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqCVilCoO-wq"
   },
   "source": [
    "우선 Keras의 [순차](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) 모델 클래스를 사용하여 데이터가 연속으로 통과할 일련의 레이어를 보유한 모델의 인스턴스를 인스턴스화하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "VXRo3j6mO-wr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOnz6yUOO-wr"
   },
   "source": [
    "### 입력 레이어 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzs4SNr_O-wr"
   },
   "source": [
    "다음으로, 입력 레이어를 추가합니다. 이 레이어는 *밀집 연결*되어 있습니다. 따라서 포함된 각 뉴런과 가중치가 다음 레이어의 모든 뉴런에 영향을 줍니다. Keras로 이를 수행하려면 Keras의 [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) 레이어 클래스를 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "YEOIHxujO-wr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttuEsjkIO-ws"
   },
   "source": [
    "`units` 인수는 레이어 내 뉴런 수를 지정합니다. 여기서는 실험에서 선택한 `512`를 사용하겠습니다. 올바른 뉴런 수를 선택하는 것은 데이터세트의 통계적 복잡성을 없애주는 일이므로, \"데이터 사이언스\" 작업의 핵심이라 할 수 있습니다. 나중에 이 값을 시험해보며 트레이닝에 어떤 영향을 미치는지 살펴보고 이 숫자의 의미에 대한 감을 키우시기 바랍니다.\n",
    "\n",
    "활성화 함수에 대해서는 나중에 자세히 알아보겠지만 일단은 `relu` 활성화 함수를 사용하겠습니다. 간략하게 설명하자면, 이 함수는 네트워크가 일부 엄격한 선형 함수를 토대로 추측해야 하는 경우에 비해 데이터에 대한 좀 더 정교한 추측을 하는 방법을 배울 수 있게 도와줍니다.\n",
    "\n",
    "`input_shape` 값은 수신되는 데이터의 모양을 지정하며, 여기서는 784개 값으로 이루어진 1D 어레이입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "6LUZB1A6O-ws"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "um-IXhNQO-ws"
   },
   "source": [
    "### 숨겨진 레이어 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klMToqwUO-ws"
   },
   "source": [
    "이제 밀집 연결된 추가 레이어를 더해 보겠습니다. 마찬가지로, 이와 관련된 내용도 나중에 자세히 알아보겠지만, 지금은 이러한 레이어가 추측에 기여하는 더 많은 매개변수 즉, 정확한 학습을 위한 좀 더 예리한 기회를 네트워크에 제공한다는 사실을 알면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "KcSdJTxkO-ws"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units = 512, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoNa45oXO-ws"
   },
   "source": [
    "### 출력 레이어 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEe-7h-JO-ws"
   },
   "source": [
    "마지막으로, 출력 레이어를 추가하겠습니다. 이 레이어는 각 레이어의 값이 0에서 1사이의 확률이 되도록 하고 레이어의 모든 출력이 1에 추가되도록 하는 활성 함수인 `softmax`를 사용합니다. 이 경우에는 네트워크가 1에서 10까지의 가능한 범주에 속하는 단일 이미지에 대해 추측을 수행하므로 출력은 10개가 됩니다. 각 출력은 이미지가 해당 특정 클래스에 속한다는 모델의 추측(확률)을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "unWjldnBO-wt"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_k7HAbbO-wt"
   },
   "source": [
    "### 모델 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YnKHby_O-wt"
   },
   "source": [
    "Keras는 모델에 대한 읽을 수 있는 요약을 출력하는 모델 인스턴스 메서드 [요약](https://www.tensorflow.org/api_docs/python/tf/summary)을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "HEnJ6T3yO-wt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8V3g4ifO-wt"
   },
   "source": [
    "트레이닝 가능한 매개변수의 수를 확인하십시오. 이러한 각 매개변수는 트레이닝 도중에 조정 가능하며 트레이닝된 모델의 추측에 기여합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YWPu30kO-wt"
   },
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTKDFIUNO-wu"
   },
   "source": [
    "마찬가지로 좀 더 상세한 내용이 따르겠지만 실제로 데이터를 사용하여 모델을 트레이닝하기 전에 수행해야 할 마지막 단계는 모델을 [컴파일](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile)하는 것입니다. 여기서는 트레이닝 중 모델에서 성능을 파악하는 데 사용되는 [손실 함수](https://developers.google.com/machine-learning/glossary#loss)를 지정합니다. 또한 모델 트레이닝 동안 `accuracy`도 추적하도록 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "KWM69r4zO-wu"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0NY9FiFO-wu"
   },
   "source": [
    "## 모델 트레이닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiNugJu8O-wu"
   },
   "source": [
    "트레이닝 및 검증 데이터와 모델이 준비되었으니 이제 트레이닝 데이터로 모델을 트레이닝하고 검증 데이터로 이를 검증해야 합니다.\n",
    "\n",
    "\\\"데이터로 모델을 트레이닝\\\"하는 것을 흔히 \\\"모델을 데이터에 맞춘다\\\"라고도 합니다. 모델을 데이터에 맞춘다는 말은 주어지고 있는 데이터를 좀 더 정확하게 이해하기 위해 모델이 점차적으로 모양을 바꾼다는 점을 부각시킵니다.\n",
    "\n",
    "Keras로 모델을 맞추는(트레이닝하는) 경우에는 모델의 [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) 메서드를 사용합니다. 그러면 다음 인수를 예상합니다.\n",
    "\n",
    "* 트레이닝 데이터\n",
    "* 트레이닝 데이터의 레이블\n",
    "* 전체 트레이닝 데이터세트에 대해 트레이닝해야 하는 횟수(*에포크*)\n",
    "* 검증 또는 테스트 데이터 및 해당 레이블\n",
    "\n",
    "\n",
    "\n",
    "* 트레이닝 데이터\n",
    "* 트레이닝 데이터의 레이블\n",
    "* 전체 트레이닝 데이터세트에 대해 트레이닝해야 하는 횟수(*에포크*)\n",
    "* 검증 또는 테스트 데이터 및 해당 레이블\n",
    "\n",
    "아래 셀을 실행하여 모델을 트레이닝하십시오. 출력에 대해서는 트레이닝이 완료된 후에 논의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "DJh9RwfYO-wu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2010 - accuracy: 0.9379 - val_loss: 0.1083 - val_accuracy: 0.9672\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0854 - accuracy: 0.9736 - val_loss: 0.1350 - val_accuracy: 0.9611\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0577 - accuracy: 0.9812 - val_loss: 0.0897 - val_accuracy: 0.9753\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0957 - val_accuracy: 0.9737\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.0937 - val_accuracy: 0.9768\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.0911 - val_accuracy: 0.9779\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.1066 - val_accuracy: 0.9753\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.1034 - val_accuracy: 0.9775\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.1169 - val_accuracy: 0.9746\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.1048 - val_accuracy: 0.9803\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.1402 - val_accuracy: 0.9747\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.1293 - val_accuracy: 0.9777\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1242 - val_accuracy: 0.9813\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.1252 - val_accuracy: 0.9793\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.1390 - val_accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.1545 - val_accuracy: 0.9783\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.1420 - val_accuracy: 0.9782\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.1516 - val_accuracy: 0.9788\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.1348 - val_accuracy: 0.9810\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.1377 - val_accuracy: 0.9813\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, epochs=20, verbose=1, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1696 - accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1696302443742752, 0.9781000018119812]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[0].reshape(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSoV3GDyO-wu"
   },
   "source": [
    "### 정확도 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.11648715e-23 8.46877887e-16 1.33364603e-18 4.13007786e-16\n",
      "  4.04507605e-20 1.63080451e-25 1.32099550e-29 1.00000000e+00\n",
      "  2.86918866e-19 1.27525684e-10]]\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = model.predict(x_test[0].reshape(1,784))\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "prediction = np.argmax(predicted_classes)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predicted 7, Class 7')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(28,28), cmap='gray')\n",
    "plt.title(f\"Predicted {prediction}, Class {np.argmax(y_test[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-ryUV8cO-wu"
   },
   "source": [
    "5회의 에포크 각각에 대해 `accuracy` 및 `val_accuracy` 점수를 살펴보십시오. `accuracy`는 모든 트레이닝 데이터에 대한 에포크 동안의 모델 성능이 어땠는지를 명시합니다. `val_accuracy`는 모델을 트레이닝하는 데 전혀 사용되지 않는 검증 데이터에 대한 모델 성능이 어땠는지를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyHT6puQO-wv"
   },
   "source": [
    "모델이 꽤 뛰어난 성능을 보여줬습니다! 정확도는 거의 100%에 빠르게 도달했고, 이는 검증 정확도의 경우에도 비슷했습니다. 이제 수기 이미지를 정확하게 검출하고 분류하는 데 사용할 수 있는 모델이 준비되었습니다.\n",
    "\n",
    "다음 단계는 이 모델을 사용하여 처음 접하는 새로운 수기 이미지를 분류하는 것입니다. 이를 [추론](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/)이라고 부릅니다. 추론 과정은 이후 연습에서 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ok2tGcAO-wv"
   },
   "source": [
    "## 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze88VNyyO-wv"
   },
   "source": [
    "우리가 여기서 수행한 내용을 잠시 평가해 볼 가치가 있습니다. 예전에는 이러한 작업을 수행하도록 구축된 전문가 시스템이 매우 복잡했으며, 사람들은 이를 구축하느라 경력을 소비했습니다([공식 MNIST 페이지](http://yann.lecun.com/exdb/mnist/)의 참조 자료와 주요 시점에 도달한 연도 참조).\n",
    "\n",
    "MNIST는 컴퓨터 비전에 대한 기존의 영향 요인에 유용할 뿐만 아니라 뛰어난 [벤치마크](http://www.cs.toronto.edu/~serailhydra/publications/tbd-iiswc18.pdf)이자 디버깅 툴이기도 합니다. 새로운 근사한 머신 러닝 아키텍처를 작동하는 데 어려움을 겪고 계십니까? MNIST와 비교해 보십시오. 이 데이터세트에 대해 학습할 수 없다면 더 복잡한 이미지와 데이터세트에 대해 학습할 수 없을 가능성이 높습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSv4qmc7O-wv"
   },
   "source": [
    "## 메모리 지우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5inYrIuwO-wv"
   },
   "source": [
    "넘어가기 전에 다음 셀을 실행하여 GPU 메모리를 지워주시기 바랍니다. 이는 다음 노트북으로 넘어가기 위한 필수 작업입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPXLWeBZO-wv"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbgEIbFuO-wv"
   },
   "source": [
    "## 다음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FJKvvsnO-wv"
   },
   "source": [
    "이 섹션에서는 이미지 분류를 위한 단순한 뉴럴 네트워크를 구축하고 트레이닝하는 방법을 알아보았습니다. 다음 섹션에서는 직접 뉴럴 네트워크를 구축하고 데이터 준비를 수행하여 여러 이미지 분류 문제를 해결해야 합니다.\n",
    "\n",
    "이어서 [02_asl.ipynb](02_asl.ipynb)를 진행해 주시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vrsHSfxO-ww"
   },
   "source": [
    "## ☆ 추가 연습 ☆\n",
    "\n",
    "시간적 여유가 있으십니까? 다음 섹션에서는 위의 수치 중 일부에 어떻게 도달했는지에 대해 이야기하겠지만, 오늘날 자주 사용되는 기술을 개발하는 연구원이 된 느낌이 어떤 것인지를 상상해볼 수 있습니다.\n",
    "\n",
    "궁극적으로 각 뉴런은 행을 어떤 데이터에 맞추려고 시도합니다. 아래에는 몇몇 데이터포인트, 그리고 등식 [y = mx + b](https://www.mathsisfun.com/equation_of_line.html)을 사용하여 임의로 도출된 행이 있습니다.\n",
    "\n",
    "`m` 및 `b`를 변경하여 최대한 낮은 손실을 찾아보십시오. 가장 적합한 행을 어떻게 찾았습니까? 프로그램이 여러분의 전략을 따르도록 만들 수 있습니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_bxtrrOO-ww"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = -2  # -2 to start, change me please\n",
    "b = 40  # 40 to start, change me please\n",
    "\n",
    "# Sample data\n",
    "x = np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
    "y = np.array([10, 20, 25, 30, 40, 45, 40, 50, 60, 55])\n",
    "y_hat = x * m + b\n",
    "\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, y_hat, '-')\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss:\", np.sum((y - y_hat)**2)/len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7I8eEBjFO-ww"
   },
   "source": [
    "아이디어가 있습니까? 좋습니다! 넘어가기 전에 커널을 종료해 주십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVv0EX77O-ww"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "eEii8f14O-wj",
    "10idks79O-wk",
    "sI3AOItwO-wm",
    "Zzq41ZYTO-wm",
    "ryBXOszJO-wn",
    "JxOR2C9HO-wo",
    "FdNfBBvwO-wp",
    "maoh1iVjO-wq",
    "SvLbQJ3SO-wq",
    "IOnz6yUOO-wr",
    "um-IXhNQO-ws",
    "hoNa45oXO-ws",
    "F_k7HAbbO-wt",
    "6YWPu30kO-wt",
    "qSoV3GDyO-wu",
    "_Ok2tGcAO-wv",
    "sSv4qmc7O-wv",
    "mbgEIbFuO-wv",
    "7vrsHSfxO-ww"
   ],
   "name": "task1_task_01_mnist.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
